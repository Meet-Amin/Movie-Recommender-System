{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meet-Amin/Movie-Recommender-System/blob/main/reddit_mental_health_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7bfc2c0",
      "metadata": {
        "id": "f7bfc2c0"
      },
      "source": [
        "\n",
        "# Reddit Mental Health Classification Project\n",
        "# Meet Amin\n",
        "\n",
        "This project aims to predict mental health conditions based on textual data collected from Reddit. Natural language processing techniques are applied to preprocess and extract meaningful features from user posts. Machine learning models are then trained to classify and predict potential mental health risks. The study demonstrates how social media data can be leveraged for early detection and awareness of mental health concerns.\n",
        "\n",
        "> **Course Project:** Text Classification with Hugging Face & Transformers  \n",
        "> **Dataset:** `kamruzzaman-asif/reddit-mental-health-classification` (Hugging Face Datasets)\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "1. [Problem Definition](#problem)\n",
        "2. [Data Understanding](#data-understanding)\n",
        "3. [Data Preparation](#data-preparation)\n",
        "4. [Modeling](#modeling)\n",
        "5. [Evaluation](#evaluation)\n",
        "6. [Conclusion & Future Work](#conclusion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ced76dc2",
      "metadata": {
        "id": "ced76dc2"
      },
      "source": [
        "\n",
        "## 1. Problem Definition <a id=\"problem\"></a>\n",
        "\n",
        "Mental health is a sensitive topic and online communities such as Reddit are frequently used by people to share their emotions, struggles, and experiences.  \n",
        "However, the volume of posts is very large and it becomes hard to manually identify which posts may need urgent attention or belong to specific mental health categories.\n",
        "\n",
        "In this project, the goal is to:\n",
        "\n",
        "- Build a **text classification model** that predicts a label for each Reddit post related to mental health.\n",
        "- Use the publicly available **`kamruzzaman-asif/reddit-mental-health-classification`** dataset from Hugging Face.\n",
        "- Fine-tune a **transformer-based model (DistilBERT)** for this classification task.\n",
        "- Evaluate the model with appropriate metrics and visualizations.\n",
        "\n",
        "This notebook follows a standard machine learning workflow:\n",
        "\n",
        "1. **Data Understanding:** Explore the dataset, label distribution, and basic statistics.  \n",
        "2. **Data Preparation:** Clean and split the data into training and validation sets.  \n",
        "3. **Modeling:** Fine-tune a pretrained language model for text classification.  \n",
        "4. **Evaluation:** Measure performance using accuracy, precision, recall, and F1-score with clear charts.  \n",
        "5. **Conclusion:** Summarize the results and discuss limitations and future improvements.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d31fa620",
      "metadata": {
        "id": "d31fa620"
      },
      "source": [
        "## 2. Data Understanding <a id=\"data-understanding\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "659ada86",
      "metadata": {
        "id": "659ada86"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =======================\n",
        "# 2.1 Import Libraries\n",
        "# =======================\n",
        "\n",
        "# Basic libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Hugging Face datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Modeling utilities\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Better display options\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Make plots a bit larger by default\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c893f3d5",
      "metadata": {
        "id": "c893f3d5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =======================\n",
        "# 2.2 Load the Dataset\n",
        "# =======================\n",
        "\n",
        "# Load the Reddit mental health dataset from Hugging Face\n",
        "ds = load_dataset(\"kamruzzaman-asif/reddit-mental-health-classification\")\n",
        "\n",
        "# Show available splits and general info\n",
        "ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4e235d6",
      "metadata": {
        "id": "a4e235d6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =======================\n",
        "# 2.3 Convert to pandas and Inspect\n",
        "# =======================\n",
        "\n",
        "# Convert the train split to a pandas DataFrame for exploration\n",
        "df = ds[\"train\"].to_pandas()\n",
        "\n",
        "print(\"Shape of training data:\", df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ee36fc5",
      "metadata": {
        "id": "4ee36fc5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Overview of columns and data types\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb1f0ce9",
      "metadata": {
        "id": "cb1f0ce9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Quick descriptive statistics for numeric columns (including label if numeric)\n",
        "df.describe(include=\"all\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60ce0505",
      "metadata": {
        "id": "60ce0505"
      },
      "source": [
        "\n",
        "### 2.4 Encode Labels as Integers (Important Fix)\n",
        "\n",
        "The original dataset stores labels as **strings**.  \n",
        "However, PyTorch and Hugging Face's Trainer expect labels to be **integers**.\n",
        "\n",
        "Here, we:\n",
        "\n",
        "- Create a mapping from string labels â†’ integer IDs (`label2id`).  \n",
        "- Store the reverse mapping in `id2label`.  \n",
        "- Replace the `label` column with the numeric ID version.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ca6caae",
      "metadata": {
        "id": "1ca6caae"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =======================\n",
        "# 2.4 Encode labels as integers\n",
        "# =======================\n",
        "\n",
        "# Keep a copy of the original string labels\n",
        "df[\"label_str\"] = df[\"label\"]\n",
        "\n",
        "# Get sorted list of unique string labels\n",
        "unique_labels = sorted(df[\"label_str\"].unique())\n",
        "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "print(\"Label mapping (string -> id):\")\n",
        "print(label2id)\n",
        "\n",
        "# Replace 'label' column with integer IDs\n",
        "df[\"label\"] = df[\"label_str\"].map(label2id)\n",
        "\n",
        "# Check the first few rows\n",
        "df[[\"text\", \"label_str\", \"label\"]].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a20ad645",
      "metadata": {
        "id": "a20ad645"
      },
      "source": [
        "\n",
        "### 2.5 Target Labels and Basic Statistics\n",
        "\n",
        "In this section, we look at:\n",
        "\n",
        "- How many examples we have in the training data.\n",
        "- How many **unique labels/classes** are present.\n",
        "- Whether the classes are **balanced or imbalanced**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96d696cb",
      "metadata": {
        "id": "96d696cb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Count of each numeric label\n",
        "label_counts = df[\"label\"].value_counts().sort_index()\n",
        "label_counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cd7f8c0",
      "metadata": {
        "id": "4cd7f8c0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Bar plot of label distribution (absolute counts)\n",
        "plt.figure()\n",
        "sns.barplot(x=label_counts.index, y=label_counts.values)\n",
        "plt.xlabel(\"Label (id)\")\n",
        "plt.ylabel(\"Number of examples\")\n",
        "plt.title(\"Label Distribution (Counts)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Bar plot of label distribution (percentage)\n",
        "label_percent = (label_counts / label_counts.sum()) * 100\n",
        "\n",
        "plt.figure()\n",
        "sns.barplot(x=label_percent.index, y=label_percent.values)\n",
        "plt.xlabel(\"Label (id)\")\n",
        "plt.ylabel(\"Percentage (%)\")\n",
        "plt.title(\"Label Distribution (Percentage)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff7b9b79",
      "metadata": {
        "id": "ff7b9b79"
      },
      "source": [
        "\n",
        "### 2.6 Text Length Analysis\n",
        "\n",
        "Now we explore how long the posts are. This can give us a sense of:\n",
        "\n",
        "- Whether posts are typically short (a few words) or long (several paragraphs).\n",
        "- How to choose a **maximum sequence length** for the transformer model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "251b2b23",
      "metadata": {
        "id": "251b2b23"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compute length of each post in characters\n",
        "df[\"text_len\"] = df[\"text\"].astype(str).str.len()\n",
        "\n",
        "print(\"Text length (characters) - summary:\")\n",
        "df[\"text_len\"].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7c0b585",
      "metadata": {
        "id": "e7c0b585"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Histogram of text length\n",
        "plt.figure()\n",
        "sns.histplot(df[\"text_len\"], bins=50, kde=True)\n",
        "plt.xlabel(\"Text length (characters)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Post Lengths\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d217b6b",
      "metadata": {
        "id": "8d217b6b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Boxplot of text length per numeric label\n",
        "plt.figure(figsize=(9, 5))\n",
        "sns.boxplot(x=\"label\", y=\"text_len\", data=df)\n",
        "plt.xlabel(\"Label (id)\")\n",
        "plt.ylabel(\"Text length (characters)\")\n",
        "plt.title(\"Text Length by Label\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d04d6a7",
      "metadata": {
        "id": "2d04d6a7"
      },
      "source": [
        "\n",
        "### 2.7 Sample Posts\n",
        "\n",
        "It is always useful to **read a few raw examples** to understand what the data looks like in practice.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77a3fd91",
      "metadata": {
        "id": "77a3fd91"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Show a few random examples from the dataset\n",
        "df.sample(5)[[\"text\", \"label_str\", \"label\"]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55900b36",
      "metadata": {
        "id": "55900b36"
      },
      "source": [
        "\n",
        "**Observations (to fill in after running the notebook):**\n",
        "\n",
        "- Total number of training samples: *write here*.  \n",
        "- Number of unique labels: *write here*.  \n",
        "- Are some labels much more frequent than others? *comment on imbalance*.  \n",
        "- Typical length of posts (median): *write value from summary output*.  \n",
        "- Any interesting patterns from the sample posts (for example, posts containing strong emotional language, questions, etc.).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42c1f405",
      "metadata": {
        "id": "42c1f405"
      },
      "source": [
        "## 3. Data Preparation <a id=\"data-preparation\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "320512f4",
      "metadata": {
        "id": "320512f4"
      },
      "source": [
        "\n",
        "The goal of data preparation is to:\n",
        "\n",
        "1. Clean the text minimally (lowercasing, removing URLs, and extra whitespace).  \n",
        "2. Create **training** and **validation** splits.  \n",
        "3. Prepare the data in a format compatible with Hugging Face Transformers.\n",
        "\n",
        "We keep the text cleaning simple to avoid accidentally removing important context.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4d38818",
      "metadata": {
        "id": "e4d38818"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =======================\n",
        "# 3.1 Basic Text Cleaning\n",
        "# =======================\n",
        "import re\n",
        "\n",
        "def clean_text(t):\n",
        "    \"\"\"Basic cleaning: lowercase, remove URLs, and extra whitespace.\"\"\"\n",
        "    if not isinstance(t, str):\n",
        "        return \"\"\n",
        "    t = t.lower()\n",
        "    # Remove URLs\n",
        "    t = re.sub(r\"http\\S+|www\\.\\S+\", \"\", t)\n",
        "    # Remove extra spaces\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    return t\n",
        "\n",
        "# Apply cleaning to the text column\n",
        "df[\"clean_text\"] = df[\"text\"].astype(str).apply(clean_text)\n",
        "\n",
        "df[[\"text\", \"clean_text\"]].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78fc0bbb",
      "metadata": {
        "id": "78fc0bbb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =======================\n",
        "# 3.2 Train / Validation Split\n",
        "# =======================\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    stratify=df[\"label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training size:\", len(train_df))\n",
        "print(\"Validation size:\", len(val_df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfde4a88",
      "metadata": {
        "id": "bfde4a88"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Check label distribution in train and validation sets\n",
        "print(\"Train label distribution:\")\n",
        "print(train_df[\"label\"].value_counts(normalize=True).sort_index())\n",
        "\n",
        "print(\"\\nValidation label distribution:\")\n",
        "print(val_df[\"label\"].value_counts(normalize=True).sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d40896",
      "metadata": {
        "id": "b0d40896"
      },
      "source": [
        "\n",
        "**Note:**\n",
        "\n",
        "- We used **stratified splitting**, which keeps the proportion of each label similar in both training and validation sets.\n",
        "- This helps the evaluation metrics to be more reliable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "241e2f41",
      "metadata": {
        "id": "241e2f41"
      },
      "source": [
        "## 4. Modeling <a id=\"modeling\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcab8ba7",
      "metadata": {
        "id": "bcab8ba7"
      },
      "source": [
        "\n",
        "In this section we:\n",
        "\n",
        "1. Convert the pandas DataFrames into Hugging Face `Dataset` objects.  \n",
        "2. Tokenize the text using a pretrained tokenizer (`distilbert-base-uncased`).  \n",
        "3. Fine-tune a `DistilBertForSequenceClassification` model on our training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "452506b6",
      "metadata": {
        "id": "452506b6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# This cell may not be needed on some platforms\n",
        "!pip install -q transformers accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1327e2ae",
      "metadata": {
        "id": "1327e2ae"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ee3fafd",
      "metadata": {
        "id": "7ee3fafd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =======================\n",
        "# 4.1 Create HF Datasets and Tokenizer\n",
        "# =======================\n",
        "\n",
        "train_hf = Dataset.from_pandas(train_df[[\"clean_text\", \"label\"]])\n",
        "val_hf   = Dataset.from_pandas(val_df[[\"clean_text\", \"label\"]])\n",
        "\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_batch(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"clean_text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "train_tokenized = train_hf.map(tokenize_batch, batched=True)\n",
        "val_tokenized   = val_hf.map(tokenize_batch, batched=True)\n",
        "\n",
        "# Remove the original text column from the tokenized dataset\n",
        "train_tokenized = train_tokenized.remove_columns([\"clean_text\"])\n",
        "val_tokenized   = val_tokenized.remove_columns([\"clean_text\"])\n",
        "\n",
        "# Set format for PyTorch\n",
        "train_tokenized.set_format(\"torch\")\n",
        "val_tokenized.set_format(\"torch\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e0e6509",
      "metadata": {
        "id": "4e0e6509"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =======================\n",
        "# 4.2 Load the Classification Model (uses label2id / id2label)\n",
        "# =======================\n",
        "\n",
        "num_labels = len(label2id)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41d9da75",
      "metadata": {
        "id": "41d9da75"
      },
      "source": [
        "## 5. Evaluation <a id=\"evaluation\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d369bf79",
      "metadata": {
        "id": "d369bf79"
      },
      "source": [
        "\n",
        "We will train the model and then evaluate it using:\n",
        "\n",
        "- **Accuracy**  \n",
        "- **Precision, Recall, F1-score (weighted)**  \n",
        "- A **confusion matrix** to visualize where the model gets confused between classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "239b4b85",
      "metadata": {
        "id": "239b4b85"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(axis=-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average=\"weighted\", zero_division=0\n",
        "    )\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4880b789",
      "metadata": {
        "id": "4880b789"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =======================\n",
        "# 5.1 Training Configuration\n",
        "# =======================\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./reddit-mental-health-model\",\n",
        "    eval_strategy=\"epoch\", # Changed from evaluation_strategy\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized,\n",
        "    eval_dataset=val_tokenized,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# ðŸ”¹ 1. Use a smaller subset so it trains fast\n",
        "# Adjust the numbers if you want a bit more data\n",
        "small_train_dataset = train_tokenized.select(range(2000))\n",
        "small_eval_dataset  = val_tokenized.select(range(500))\n",
        "\n",
        "# ðŸ”¹ 2. Define lighter training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=1,                 # 1 epoch is enough for demo\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_ratio=0.1,\n",
        "\n",
        "    logging_steps=20,\n",
        "    eval_strategy=\"steps\", # Corrected from evaluation_strategy\n",
        "    eval_steps=100,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "\n",
        "    report_to=\"none\",                   # disable wandb, etc.\n",
        "    no_cuda=False,                      # use GPU if available\n",
        "    fp16=True,                          # mixed precision on GPU (ignored on CPU)\n",
        "    max_steps=500                       # hard cap on steps (optional but safe)\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# =======================\n",
        "# 5.2 Train the Model\n",
        "# =======================\n",
        "train_result = trainer.train()\n",
        "train_result"
      ],
      "metadata": {
        "id": "KzRrWM4jGEte"
      },
      "id": "KzRrWM4jGEte",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "073beec9",
      "metadata": {
        "id": "073beec9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =======================\n",
        "# 5.3 Final Evaluation on Validation Set\n",
        "# =======================\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "eval_results\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n"
      ],
      "metadata": {
        "id": "MNkvxK-iqsTa"
      },
      "id": "MNkvxK-iqsTa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "759ea083",
      "metadata": {
        "id": "759ea083"
      },
      "source": [
        "\n",
        "**How to interpret these results (to discuss in your own words):**\n",
        "\n",
        "- **Accuracy:** Overall proportion of correct predictions.  \n",
        "- **Precision:** Of the posts predicted in a certain class, how many were actually in that class.  \n",
        "- **Recall:** Of the posts that truly belong to a class, how many did the model correctly find.  \n",
        "- **F1-score:** Harmonic mean of precision and recall (balances both).  \n",
        "- **Confusion matrix:** Shows which classes are often confused with each other.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff3f8462",
      "metadata": {
        "id": "ff3f8462"
      },
      "source": [
        "## 6. Conclusion & Future Work <a id=\"conclusion\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42e69459",
      "metadata": {
        "id": "42e69459"
      },
      "source": [
        "\n",
        "### 6.1 Summary of Findings\n",
        "\n",
        "In this project, we:\n",
        "\n",
        "1. Loaded and explored the **Reddit mental health** dataset.  \n",
        "2. Observed the **label distribution**, typical **post lengths**, and sample posts.  \n",
        "3. Encoded string labels into **integer IDs** to make them compatible with PyTorch.  \n",
        "4. Performed minimal text cleaning and created **train/validation** splits.  \n",
        "5. Fine-tuned a **DistilBERT** model for sequence classification.  \n",
        "6. Evaluated performance using accuracy, precision, recall, F1-score, and a confusion matrix.\n",
        "\n",
        "After running the notebook, you should summarize here in your own words:\n",
        "\n",
        "- The final evaluation metrics (accuracy, F1, etc.).  \n",
        "- Which classes the model handled well and which were more difficult.  \n",
        "- Any signs of class imbalance impacting performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a19185a4",
      "metadata": {
        "id": "a19185a4"
      },
      "source": [
        "\n",
        "### 6.2 Limitations\n",
        "\n",
        "Some possible limitations to mention:\n",
        "\n",
        "- **Dataset Size & Bias:** The dataset may not fully represent all types of mental health content on the internet.  \n",
        "- **Label Noise:** Labels might not be perfect, especially if they were created automatically or by a small group of annotators.  \n",
        "- **Context:** Reddit posts can be highly contextual; sometimes the label may depend on previous posts or comments that are not included.  \n",
        "- **Model Complexity:** DistilBERT is powerful but still has limitations when detecting subtle emotions or sarcasm.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fba6fae0",
      "metadata": {
        "id": "fba6fae0"
      },
      "source": [
        "\n",
        "### 6.3 Future Work\n",
        "\n",
        "Ideas to improve this project:\n",
        "\n",
        "- Experiment with **different transformer models** (e.g., BERT, RoBERTa).  \n",
        "- Use **class weighting** or **focal loss** if the dataset is highly imbalanced.  \n",
        "- Try more advanced **text cleaning** or domain-specific pre-processing.  \n",
        "- Perform **hyperparameter tuning** (learning rate, batch size, epochs).  \n",
        "- Deploy the model as a simple **web app** to classify new Reddit-style posts in real time.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c3dEPacpQZhA"
      },
      "id": "c3dEPacpQZhA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}